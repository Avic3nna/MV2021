{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#take picture from video stream on pressing escape key\n",
    "#pictures are taken with 2 top horizontal light strips and the table light towards the administration door (with blinders closed)\n",
    "import cv2\n",
    "\n",
    "cv2.namedWindow(\"tripod cam\")\n",
    "vc = cv2.VideoCapture(1)\n",
    "\n",
    "if vc.isOpened(): # try to get the first frame\n",
    "    rval, frame = vc.read()\n",
    "else:\n",
    "    rval = False\n",
    "\n",
    "while rval:\n",
    "    cv2.imshow(\"tripod cam\", frame)\n",
    "    rval, frame = vc.read()\n",
    "    key = cv2.waitKey(20)\n",
    "    if key == 27: # exit on ESC\n",
    "        break\n",
    "\n",
    "cv2.imwrite('Images/testresult1.png', frame)\n",
    "vc.release()\n",
    "cv2.destroyWindow(\"tripod cam\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#live filter application (1 mask at a time)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# define the list of boundaries\n",
    "#we need red white and black\n",
    "#https://www.etutorialspoint.com/index.php/329-detect-specific-color-from-image-using-python-opencv\n",
    "boundaries = [#BGR\n",
    "\t([165, 135, 70], [185, 160, 120]), #blue pills\n",
    "]\n",
    "\n",
    "cv2.namedWindow(\"tripod cam\")\n",
    "vc = cv2.VideoCapture(0)\n",
    "\n",
    "if vc.isOpened(): # try to get the first frame\n",
    "    rval, img = vc.read()\n",
    "else:\n",
    "    rval = False\n",
    "\n",
    "while rval:\n",
    "    rval, img = vc.read()\n",
    "    key = cv2.waitKey(20)\n",
    "\n",
    "    # loop over the boundaries\n",
    "    for (lower, upper) in boundaries:\n",
    "        # create NumPy arrays from the boundaries\n",
    "        lower = np.array(lower, dtype = \"uint8\")\n",
    "        upper = np.array(upper, dtype = \"uint8\")\n",
    "        # find the colors within the specified boundaries and apply\n",
    "        # the mask\n",
    "        mask = cv2.inRange(img, lower, upper)\n",
    "        output = cv2.bitwise_and(img, img, mask = mask)\n",
    "        # show the images\n",
    "        cv2.imshow(\"images\", np.hstack([img, output]))\n",
    "        key = cv2.waitKey(20)\n",
    "\n",
    "    if key == 27: # exit on ESC\n",
    "        break\n",
    "\n",
    "vc.release()\n",
    "cv2.destroyWindow(\"images\")\n",
    "cv2.destroyWindow(\"tripod cam\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(r\"G:\\\\My Drive\\\\1. EIT Digital master\\\\Estland\\\\Semester 1\\\\Machine vision\\\\MV2021\\\\Homework 1\\\\Python OpenCV2\\\\Images\\\\testresult3.png\")\n",
    "\n",
    "# define the list of boundaries\n",
    "boundaries = [ #BGR lower limit - upper limit\n",
    "\t([80, 75, 20], [140, 125, 60]), #blue\n",
    "\t([0, 40, 140], [10, 85, 210]), #orange\n",
    "\t([20, 100, 120], [80, 165, 185]) #yellow\n",
    "]\n",
    "\n",
    "# loop over the boundaries\n",
    "i = 0\n",
    "colour_list = ['blue', 'orange', 'yellow']\n",
    "\n",
    "for (lower, upper) in boundaries:\n",
    "    # create NumPy arrays from the boundaries\n",
    "    lower = np.array(lower, dtype = \"uint8\")\n",
    "    upper = np.array(upper, dtype = \"uint8\")\n",
    "    # find the colors within the specified boundaries and apply\n",
    "    # the mask\n",
    "\n",
    "    # Gaussian blur: Kernel size: 15x15 Sigma=2\n",
    "    blur = cv2.GaussianBlur(img, (15, 15), 2) #blur image https://stackoverflow.com/questions/45943602/removing-pixels-less-than-n-sizenoise-in-an-image-open-cv-python\n",
    "\n",
    "    # Apply color mask to have different images for each color\n",
    "    mask = cv2.inRange(blur, lower, upper)\n",
    "\n",
    "    output = cv2.bitwise_and(img, img, mask = mask)\n",
    "    kernel = np.ones((3,3), dtype = np.uint8)\n",
    "\n",
    "    # Erosion to avoid noise connected components\n",
    "    output = cv2.erode(output, kernel) #to get rid of the yellow spots on the silver parts\n",
    "\n",
    "    # Denoising using Non-local Means\n",
    "    output = cv2.fastNlMeansDenoisingColored(output) #get rid of noise https://opencv24-python-tutorials.readthedocs.io/en/latest/py_tutorials/py_photo/py_non_local_means/py_non_local_means.html\n",
    "    \n",
    "    # counting the contours and thresholding them to count the pills\n",
    "    # in order to do so, the image needs to be thresholded (binary) first\n",
    "    output_bw = cv2.cvtColor(output, cv2.COLOR_BGR2GRAY)\n",
    "    ret,thresh1 = cv2.threshold(output_bw,127,255, cv2.THRESH_BINARY)\n",
    "    contours, hierarchy = cv2.findContours(output_bw, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Take into account only connected components bigger than 1500 pixels (Avoid counting noise elements)\n",
    "    threshold_area = 1500\n",
    "    pill_count = 0\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if(area > threshold_area):\n",
    "            pill_count += 1\n",
    "\n",
    "    # show the images\n",
    "    cv2.imshow(\"%s pill count: %d\" %(colour_list[i], pill_count), output) #np.hstack([img, output])\n",
    "    cv2.imwrite('Images/testresult3_output_img%i.png'%i, output)\n",
    "    i += 1\n",
    "    cv2.waitKey(0)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "interpreter": {
   "hash": "d2f780d3fa0f233da220727534c26375caac5692cb408a3c2164f85e81e52cd5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}